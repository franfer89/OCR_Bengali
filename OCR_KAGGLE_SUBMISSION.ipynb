{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Bengali\n",
    "# KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import gc\n",
    "import os\n",
    "\n",
    "\n",
    "## To see files in Kaggle folder\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#for dirname, _, filenames in os.walk('/Users/franf/Python/Projects/OCR_BANGALI'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and resize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def resize(X,size=128):\n",
    "    ## This function resizes each image to size x size. It also inverses the image and normalize it. \n",
    "    ## INPUT\n",
    "    ##### X numpy array of 4D: (training samples, X, Y, Channels)\n",
    "    ##### size: new size of image\n",
    "    ## OUTPUT\n",
    "    ##### XP tf tensor: X resized and normalized\n",
    "    X=tf.math.divide(tf.subtract(255.0,X),255.0)\n",
    "    XP=tf.image.resize(X,[size,size])\n",
    "    return XP\n",
    "\n",
    "def crop_and_resize(X,size=64,threshold=0.01):\n",
    "    ## This function crops and resizes each image to size x size. It also inverses the image and normalize it.\n",
    "    ## Operations:\n",
    "    ## (1) Normalization to 1\n",
    "    ## (2) Reverse image\n",
    "    ## (3) Crop to a rectangle that assure that ((1-threshold*2)x100)% of the sum of the value of pixels is maintained.\n",
    "    ## (4) resizes to size x size\n",
    "    ## INPUT\n",
    "    ##### X numpy array of 4D: (training samples, X, Y, Channels)\n",
    "    ##### size: new size of image\n",
    "    ##### threshold: see (3) operation\n",
    "    ## OUTPUT\n",
    "    ##### X_crop tf tensor: X crop, resized and normalized\n",
    "    \n",
    "    ## (1) Normalization \n",
    "    X=tf.math.divide(tf.subtract(255.0,X),255.0)\n",
    "    ## (2) Reverse\n",
    "    Xreverse=tf.reverse(tf.reverse(X,[1]),[2])\n",
    "    \n",
    "    shapeX=tf.shape(X)\n",
    "    m0=shapeX[0]\n",
    "    m1=shapeX[1]\n",
    "    m2=shapeX[2]\n",
    "    m3=shapeX[3]\n",
    "    \n",
    "    ## (3) Calculation of rectangles to crop\n",
    "    X_aux=tf.math.multiply(tf.cast(X,tf.float32),tf.cast((tf.math.greater(X,0.5)),tf.float32))\n",
    "    suma=tf.reshape(tf.math.reduce_sum(tf.math.reduce_sum(tf.math.reduce_sum(X_aux,axis=1),axis=1),axis=1),[-1,1])\n",
    "    y  = tf.math.divide(tf.math.cumsum(tf.math.reduce_sum(tf.reshape(X_aux,[m0,m1,m2]),axis=2),axis=1),suma)\n",
    "    \n",
    "    y1 = tf.cast(tf.math.greater(y,threshold),tf.float32)\n",
    "    y1 = tf.reshape(tf.math.argmax(y1,axis=1),[-1,1])\n",
    "    y1 = tf.cast(y1,tf.float32)/tf.cast(m1,tf.float32)*0.6\n",
    "    \n",
    "    y2 = tf.cast(tf.math.greater(y,1.0-threshold),tf.float32)\n",
    "    y2 = tf.reshape(tf.math.argmax(y2,axis=1),[-1,1])\n",
    "    y2 = 1.0-(1.0-tf.cast(y2,tf.float32)/tf.cast(m1,tf.float32))*0.6\n",
    "    \n",
    "    x  = tf.math.divide(tf.math.cumsum(tf.math.reduce_sum(tf.reshape(X_aux,[m0,m1,m2]),axis=1),axis=1),suma)\n",
    "    x1 = tf.cast(tf.math.greater(x,threshold),tf.float32)\n",
    "    x1 = tf.reshape(tf.math.argmax(x1,axis=1),[-1,1])\n",
    "    x1 = tf.cast(x1,tf.float32)/tf.cast(m2,tf.float32)*0.6\n",
    "\n",
    "    x2 = tf.cast(tf.math.greater(x,1.0-threshold),tf.float32)\n",
    "    x2 = tf.reshape(tf.math.argmax(x2,axis=1),[-1,1])\n",
    "    x2 = 1.0-(1.0-tf.cast(x2,tf.float32)/tf.cast(m2,tf.float32))*0.6\n",
    "      \n",
    "    boxes=tf.cast(tf.reshape(tf.transpose(tf.stack([y1,x1,y2,x2])),[m0,4]),tf.float32)\n",
    "    \n",
    "    ## (3) & (4) Crop and resize\n",
    "    X_crop=tf.image.crop_and_resize(X,\n",
    "                                     boxes=boxes,\n",
    "                                     box_indices=tf.range(0,m0,dtype=tf.int32),\n",
    "                                     crop_size=[size,size],\n",
    "                                     method='bilinear'\n",
    "                                     )\n",
    "    return X_crop\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers to pre-process during testing and avoid memory exceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, size=128):\n",
    "        super(ResizeLayer, self).__init__()\n",
    "        self.size = size\n",
    "    def build(self, input_shape):\n",
    "        None\n",
    "    def call(self, input):\n",
    "        return resize(input,self.size)\n",
    "    \n",
    "class CropResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, size=128):\n",
    "        super(CropResizeLayer, self).__init__()\n",
    "        self.size = size\n",
    "    def build(self, input_shape):\n",
    "        None\n",
    "    def call(self, input):\n",
    "        return crop_and_resize(input,self.size) \n",
    "    \n",
    "class onlyone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(onlyone, self).__init__()\n",
    "    def build(self, input_shape):\n",
    "        None\n",
    "    def call(self, input):\n",
    "        depth = input.shape[1]\n",
    "        indices = tf.math.argmax(input,axis=1)\n",
    "        return tf.one_hot(indices, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path2models='/Users/franf/Python/Projects/OCR_BANGALI/Trained models/'\n",
    "## Models with 64x64 input\n",
    "Model64 = ['OCRB64_DenseNet121_V20200306.h5',\n",
    "          'OCRB64_DenseNet169_V20200306.h5',\n",
    "          'OCRB64_ResNet50V2_V20200305.h5',\n",
    "          'OCRB64MU_DenseNet121_V20200309.h5']\n",
    "## Models with 128x128 input\n",
    "Model128 = ['OCRB128_DenseNet121_V20200304.h5',\n",
    "           'OCRB128_DenseNet169_V20200228.h5',\n",
    "           'OCRB128_ResNet50V2_V20200304_V2.h5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 137, 236, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "crop_resize_layer (CropResizeLa (None, 64, 64, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "resize_layer (ResizeLayer)      (None, 128, 128, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_9 (Model)                 [(None, 168), (None, 7352856     crop_resize_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "model_13 (Model)                [(None, 168), (None, 13124632    crop_resize_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "model_8 (Model)                 [(None, 168), (None, 24146392    crop_resize_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 168), (None, 7663896     crop_resize_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 [(None, 168), (None, 7352856     resize_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   [(None, 168), (None, 13124632    resize_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 [(None, 168), (None, 24146392    resize_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 168)          0           model_9[1][0]                    \n",
      "                                                                 model_13[1][0]                   \n",
      "                                                                 model_8[1][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "                                                                 model[1][0]                      \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 11)           0           model_9[1][1]                    \n",
      "                                                                 model_13[1][1]                   \n",
      "                                                                 model_8[1][1]                    \n",
      "                                                                 model_1[1][1]                    \n",
      "                                                                 model_2[1][1]                    \n",
      "                                                                 model[1][1]                      \n",
      "                                                                 model_5[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7)            0           model_9[1][2]                    \n",
      "                                                                 model_13[1][2]                   \n",
      "                                                                 model_8[1][2]                    \n",
      "                                                                 model_1[1][2]                    \n",
      "                                                                 model_2[1][2]                    \n",
      "                                                                 model[1][2]                      \n",
      "                                                                 model_5[1][2]                    \n",
      "==================================================================================================\n",
      "Total params: 96,911,656\n",
      "Trainable params: 96,227,944\n",
      "Non-trainable params: 683,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_CHANNELS=1\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "#SIZE = 64 or 128\n",
    "\n",
    "inputs =  tf.keras.layers.Input(shape = (HEIGHT,WIDTH,1))\n",
    "model_R  =  ResizeLayer(128)(inputs)\n",
    "model_CR  =  CropResizeLayer(64)(inputs)\n",
    "\n",
    "my0=[]\n",
    "my1=[]\n",
    "my2=[]\n",
    "for i in range(len(Model64)):\n",
    "    model=tf.keras.models.load_model(Path2models+Model64[i])\n",
    "    miy0,miy1,miy2 =  model(model_CR)\n",
    "    # If it is desired one_hot before adding, uncomment this:\n",
    "    # miy0==onlyone()(miy0)\n",
    "    # miy1==onlyone()(miy1)\n",
    "    # miy2==onlyone()(miy2)\n",
    "    my0.append(miy0)\n",
    "    my1.append(miy1)\n",
    "    my2.append(miy2)\n",
    "\n",
    "for i in range(len(Model128)):\n",
    "    model=tf.keras.models.load_model(Path2models+Model128[i])\n",
    "    miy0,miy1,miy2 =  model(model_R)\n",
    "    # If it is desired one_hot before adding, uncomment this:\n",
    "    # miy0==onlyone()(miy0)\n",
    "    # miy1==onlyone()(miy1)\n",
    "    # miy2==onlyone()(miy2)\n",
    "    my0.append(miy0)\n",
    "    my1.append(miy1)\n",
    "    my2.append(miy2)\n",
    "\n",
    "grapheme = tf.keras.layers.Add()(my0)\n",
    "vowel = tf.keras.layers.Add()(my1)\n",
    "consonant = tf.keras.layers.Add()(my2)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[grapheme, vowel, consonant])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = ['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32332)\n",
      "(3, 137, 236, 1)\n",
      "(3, 32332)\n",
      "(3, 137, 236, 1)\n",
      "(3, 32332)\n",
      "(3, 137, 236, 1)\n",
      "(3, 32332)\n",
      "(3, 137, 236, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  target\n",
       "0  Test_0_consonant_diacritic       0\n",
       "1        Test_0_grapheme_root       3\n",
       "2      Test_0_vowel_diacritic       0\n",
       "3  Test_1_consonant_diacritic       0\n",
       "4        Test_1_grapheme_root      93"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_dict = {\n",
    "    'grapheme_root': [],\n",
    "    'vowel_diacritic': [],\n",
    "    'consonant_diacritic': []\n",
    "}\n",
    "\n",
    "components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n",
    "target=[] # model predictions placeholder\n",
    "row_id=[] # row_id place holder\n",
    "for i in range(4):\n",
    "    #df_test_img = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)) \n",
    "    df_test_img = pd.read_parquet('/Users/franf/Python/Projects/OCR_BANGALI/Data/test_image_data_{}.parquet'.format(i)) \n",
    "    df_test_img.set_index('image_id', inplace=True)\n",
    "    print(df_test_img.shape)\n",
    "    TESTX=df_test_img.iloc[:, :].values.reshape(-1, HEIGHT, WIDTH,1)\n",
    "    print(TESTX.shape)\n",
    "    \n",
    "    preds = model.predict(TESTX)\n",
    "    \n",
    "    for i, p in enumerate(preds_dict):\n",
    "        preds_dict[p] = np.argmax(preds[i], axis=1)\n",
    "\n",
    "    for k,id in enumerate(df_test_img.index.values):  \n",
    "        for i,comp in enumerate(components):\n",
    "            id_sample=id+'_'+comp\n",
    "            row_id.append(id_sample)\n",
    "            target.append(preds_dict[comp][k])\n",
    "    del df_test_img\n",
    "    del TESTX\n",
    "    gc.collect()\n",
    "\n",
    "df_sample = pd.DataFrame(\n",
    "    {\n",
    "        'row_id': row_id,\n",
    "        'target':target\n",
    "    },\n",
    "    columns = ['row_id','target'] \n",
    ")\n",
    "df_sample.to_csv('submission.csv',index=False)\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
